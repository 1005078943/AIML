# 1.1概论
在互联网发达的今天，很多知识都可以从网络上找到，但是网络上的博客、文章的质量参差不齐，或者重点不明确，或者直接把别人的博客抄袭过来。这种状况使得广大的初学者们学习起来很困难，甚至误入歧途，增加了学习曲线的陡峭程度。当然也有很多博主非常非常负责任，文章质量很高，只是连续度不够，正看得过瘾的时候，没有后续章节了，无法形成知识体系。

初学者也可以选择看一些教材或者理论书籍，但是，一个鸡生蛋蛋生鸡的问题出现了：如果你不懂，那么看完了理论你还是不会懂；如果你懂了，那么你就没必要看理论。这也是很多教材或者理论书籍的缺憾。

笔者也看过吴恩达老师的课，理论知识讲得由浅入深，还是非常清楚的，虽然代码示例基本没有，但仍然强烈建议大家去看。笔者的心得是：视频可以事先缓存在手机中，利用一些时间片段就可以学习了。

社会上还有一些网课，在线讲解深度学习的知识，笔者也参加了几个团购，老师和助教一般都很负责任，最后可以回看录像，下载PPT课件。这些课程一般偏重于工程项目，讲解深度学习框架和工具的使用，即教大家如何使用工具建模、训练等等，也是很有帮助的。但对于初学者来说，理解一个新概念可能需要前面很多个已有知识点的支撑，门槛过高，一下子就变得很沮丧。或者是知其然而不知其所以然，最后沦为调参工程师，职业发展受到了限制。

还是应了那句古话：授人以鱼不如授人以渔。经历了以上那些学习经历，程序员出身的笔者迫切感觉到应该有一种新的学习体验，在“做中学”，用写代码的方式把一些基础的理论复现一遍，可以深刻理解其内涵，并能扩充其外延，使读者得到举一反三的泛化能力。

笔者总结了自身的学习经历后，把深度学习的入门知识归纳成了9个步骤，简称为9步学习法：

1. 基本概念
2. 线性回归
3. 线性分类
4. 非线性回归
5. 非线性分类
6. 模型的推理与部署
7. 深度神经网络
8. 卷积神经网络
9. 循环神经网络

笔者看到过的很多书籍是直接从第7步起步的，其基本假设是读者已经掌握了前面的知识。但是对于从零开始的初学者们，这种假设并不正确。

在后面的讲解中，我们一般会使用如下方式进行：

1. 提出问题：先提出一个与现实相关的假想问题，为了由浅入深，这些问题并不复杂，是实际的工程问题的简化版本。
2. 解决方案：用神经网络的知识解决这些问题，从最简单的模型开始，一步步到复杂的模型。
3. 原理分析：使用基本的物理学概念或者数学工具，理解神经网络的工作方式。
4. 可视化理解：可视化是学习新知识的重要手段，由于我们使用了简单案例，因此可以很方便地可视化。

原理分析和可视化理解也是本书的一个特点，试图让神经网络是可以解释的，而不是盲目地使用。

还有一个非常重要的地方，我们还有配套的Python代码，除了一些必要的科学计算库和绘图库，如NumPy和Matplotlib等，我们没有使用任何已有的深度学习框架，而是带领大家从零开始搭建自己的知识体系，从简单到复杂，一步步理解深度学习中的众多知识点。

对于没有Python经验的朋友来说，通过阅读示例代码，也可以起到帮助大家学习Python的作用，一举两得。随着问题的难度加深，代码也会增多，但是前后都有继承关系的，最后的代码会形成一个小的框架，笔者称之为Mini-Framework，可以用搭积木的方式调用其中的函数来搭建深度学习的组件。

这些代码都是由笔者亲自编写调试的，每章节都可以独立运行，得到相关章节内所描述的结果，包括打印输出和图形输出。

另外，为了便于理解，笔者绘制了大量的示意图，数量是同类书籍的10倍以上。一图顶万字，相信大家会通过这些示意图快速而深刻地理解笔者想要分享的知识点，使大家能够从真正的“零”开始，对神经网络、深度学习有基本的了解，并能动手实践。

对于读者的要求：

1. 学过高等数学中的线性代数与微分
2. 有编程基础，可以不会Python语言，因为可以从示例代码中学得
3. 思考 + 动手的学习模式

可以帮助读者达到的水平：

1. 可以判断哪些任务是机器学习可以实现的，哪些是科学幻想，不说外行话
2. 深刻了解神经网络和深度学习的基本理论
3. 培养举一反三的解决实际问题的能力
4. 得到自学更复杂模型和更高级内容的能力
5. 对于天资好的读者，可以培养研发新模型的能力

# 1.2人工智能发展简史
既然这本书是人工智能入门书，我们就要先讲清楚一些定义。我们从“智能”开始。从计算机科学出现之时，科学家就开始探讨计算机是否能有“智能”。

1950年，英国科学家艾伦图灵发表了论文讨论创造出具有真正智能的机器的可能性，并提出了著名的图灵测试：如果一台机器能够与人类展开对话而不能被辨别出其机器身份，那么称这台机器具有智能。现在活跃于电脑，手机，还有各种硬件上的“智能助手”在各自的功能领域，通常被大众认为挺有智能的。

但是那些“智能助手”，聊天机器人真的有智能么？1980年就有学者（John Searle）提到了中文房间问题，如图1-1所示。

<img src="https://aiedugithub4a2.blob.core.windows.net/a2-images/Images/1/image1.png" width="500" />

图1-1 中文房间问题

一个对中文一窍不通，只说英语的人关在一个封闭房间中。房间里有一本用英文写成的手册，指示该如何处理收到的汉语信息及如何以汉语相应地回复。房外的人向房间内递进用中文写成的问题。房内的人便按照手册的说明，查找到合适的指示，将相应的中文字符组合成对问题的解答，并将答案递出。

房间外面的人看到自己递进去的中文输入能得到回答，很可能就会认为房间内的人有智能，懂中文，就像现在的聊天机器人那样，那么这是“智能”么？读者们如果写过一些程序，就会想，我也可以写一个程序，根据一些规则和已有的数据，和用户进行某种程度的智能对话，那么AI和我的程序有区别么？图1-2是一个非常简单的程序流程图。

<img src="https://aiedugithub4a2.blob.core.windows.net/a2-images/Images/1/image2.png"  width="500" />

图1-2 简单的程序流程图

程序接到用户的输入句子后，如果不是结束会话的指令，就在一个数据库中寻找合适的回答句子，然后根据情况准备输出，然后再继续循环……

从1956年的达特茅斯会议开始，人工智能（Artificial Intelligence，AI）作为一个专门的研究领域出现，经历了超过半个世纪的起伏，终于在2007年前后，迎来了又一次大发展。图1-3展现了人工智能历史的一些里程碑事件。

<img src="https://aiedugithub4a2.blob.core.windows.net/a2-images/Images/1/image3.png" />

图1-3 人工智能发展史

从图1-3中我们可以看出，人工智能的发展，有这样起伏的模式：

1.  研究（包括技术）取得进展。
2.  研究的进展让人们看到人工智能的潜力，产生非常乐观的期望，例如在1958年到1970年间科学家对人工智能各种突破的预计，当然他们的绝大多数预计都太乐观了。
3.  上述过高的期望让产业界开始热情地开发各种应用。
4.  但应用未能全部满足期望，于是人工智能行业进入低谷，直到下一波研究和技术取得突破性进展。在2007年之后，是大规模的数据和廉价的计算能力，让神经网络技术再度兴起，成为AI领域的明星技术。

# 1.3人工智能的定义
要实现某种狭义的人工智能，我们很自然地想到，如果我们能让运行程序的电脑来学习并自动掌握某些规律，那该多好啊，这就是“机器学习”。机器学习在几十年的发展历史中，产生了很多技术，这些技术都有下面的共性：

1. 选择一个模型结构（例如逻辑回归，决策树等），这就是上面说的程序。
2. 用训练数据（输入和输出）输入模型。这就是上面的经验（E）。
3. 通过不断执行任务（T）并衡量结果（P），让P
不断提高，直到达到一个满意的值。

那么，机器学习的各种方法是如何从经验中学习呢？我们可以大致地分为下面三种类型：

1. 监督学习（Supervised Learning）

    通过标注的数据来学习，例如，程序通过学习标注了正确答案的手写数字的图像数据，它就能认识其他的手写数字。

2. 无监督学习（Unsupervised Learning）

    通过没有标注的数据来学习。这种算法可以发现数据中自然形成的共同特性（聚类），可以用来发现不同数据之间的联系，例如，买了商品A的顾客往往也购买了商品B。

3. 强化学习（Reinforcement Learning）

    我们可以让程序选择和它的环境互动（例如玩一个游戏），环境给程序的反馈是一些“奖励”（例如游戏中获得高分），程序要学习到一个模型，能在这种环境中得到高的分数，不仅是当前局面要得到高分，而且最终的结果也要是高分才行。

综合来看，如果我们把机器学习当作一个小孩，那么，教育小孩的方式就有根据正确答案指导学习（监督学习）；根据小孩实践的过程给予各种鼓励（强化学习）；还有自由探索世界，让小孩自己总结规律（无监督学习）。

机器学习领域出现了各种模型，其中，神经网络模型是一个重要的方法，它的原型在1943就出现了，在生物神经网络中，每个神经元与其他神经元相连，当它兴奋时，就会像相邻的神经元发送化学物质，从而改变这些神经元内的电位；如果某神经元的电位超过了一个阈值，那么它就会被激活（兴奋），向其他神经元发送化学物质。把许多这样的神经元按照一定的层次结构连接起来，我们就构建了一个神经网络$^{[3]}$。图1-4是M-P神经元模型的示意图。

<img src="https://aiedugithub4a2.blob.core.windows.net/a2-images/Images/1/image5.png" width="500" />

图1-4 M-P神经元模型

随着数据的丰富和机器算力的增强，人们不断增加神经网络的层次数目，相邻层次之间的输入输出由非线性函数来控制，这就产生了DNN（深度神经网络）。DNN在最近十年给人工智能领域带来了新的生机，并在图像分类、语音识别、自然语言处理等方面取得了重大突破。

随着人们不断的调整网络结构，DNN也演变成许多不同的网络拓扑结构，例如CNN（卷积神经网络），RNN（循环神经网络），LSTM（长期短期记忆），GAN（生成对抗网络），Transfer Learning（迁移学习）等，这些模型还在不断演化中。

训练AI模型，需要一系列专门的工具，业界有不少成熟的训练平台（TensorFlow，PyTorch，MXNet等），这些平台也在不断演化，支持新的模型，提高训练的效率，改进易用性，等等。当然我们也可以自己开发平台来训练，本书的大部分章节就是带领读者自己动手打造一个小型的开发平台。

# 1.4范式的演化
## 第一阶段：经验

从几千年前到几百年前，人们描述自然现象，归纳总结一些规律。

人类最早的科学研究，主要以记录和描述自然现象为特征，不妨称之为称为“经验归纳”（第一范式）。人们看到自然现象，凭着自己的体验总结一些规律，并把规律推广到其他领域。这些规律通常是定性的，不是定量的。有时看似符合直觉，其实原理是错误的；有时在某个局部有效，但是推广到其他领域则不能适用；有些论断来自权威，导致错误总结也流传了很多年无人挑战。例如，我们看到日月星辰都围绕我们转，地心说很自然就产生了； 我们在生活中观察不同质量的物体运动的情况，也凭直觉推断“物体的下落速度和重量成正比”。人们对于不同的观点，也没有严谨地定义试验来证明。例如中国古代“两小儿辩日”的故事：

> 孔子东游，见两小儿辩日，问其故。
>
> 一儿曰：“我以日始出时去人近，而日中时远也。”
>
> 一儿以日初出远，而日中时近也。
>
> 一儿曰：“日初出大如车盖，及日中则如盘盂，此不为远者小而近者大乎？”
>
> 一儿曰：“日初出沧沧凉凉，及其日中如探汤，此不为近者热而远者凉乎？”
>
> 孔子不能决也。
>
> 两小儿笑曰：“孰为汝多知乎？”

两个小孩通过视觉效果和身体对温度的感觉来判断太阳和地球的距离变化，而且小孩子们把主观的“我觉得它远”完全等同于“物体离我远”这样一个客观事实。这是一个多么大胆的思维跳跃啊，孔子当时也没有能设计一个试验来证伪某一个观点，只能诚实地表示“不能决”，还遭到小孩笑话。

## 第二阶段：理论

这一阶段，科学家们开始明确定义，速度是什么，质量是什么，化学元素是什么（不再是五行和燃素）……也开始构建各种模型，在模型中尽量撇除次要和无关因素，例如我们在中学的物理实验中，要假设“斜面足够光滑，无摩擦力”，“空气阻力可以忽略不计”，等等。在这个理论演算（Theoretical）阶段，以伽利略为代表的科学家，开启了现代科学之门。他在比萨斜塔做的试验（图1-9）推翻了两千多年来大家想当然的“定律”。

<img src="https://aiedugithub4a2.blob.core.windows.net/a2-images/Images/1/image10.jpeg" />

图1-9 伽利略在比萨斜塔做试验

在理论演算阶段，不但要定性，而且要定量，要通过数学公式严格的推导得到结论。我们现在知道真空中自由落体下落的公式：

$$h = \frac{1}{2}gt^{2}$$

$h$ 是下落的高度，$g$ 是重力加速度，$t$ 是运动时间。

这个公式里没有物体的质量，所以我们可以说，在真空中，自由落体下落的速度的确和物体的质量无关。

## 第三阶段：计算仿真

从二十世纪中期开始，利用电子计算机对科学实验进行模拟仿真的模式得到迅速普及，人们可以对复杂现象通过模拟仿真，推演更复杂的现象，典型案例如模拟核试验、天气预报等。这样计算机仿真越来越多地取代实验，逐渐成为科研的常规方法。科学家先定义问题，确认假设，再利用数据进行分析和验证。

## 第四阶段：数据探索

最后我们到了“数据探索”（Data Exploration）阶段。在这个阶段，科学家收集数据，分析数据，探索新的规律。在深度学习的浪潮中出现的许多结果就是基于海量数据学习得来的。有些数据并不是从现实世界中收集而来，而是由计算机程序自己生成，例如，在AlphaGo算法训练的过程中，它和自己对弈了数百万局，这个数量大大超过了所有记录下来的职业选手棋谱的数量。

# 1.5神经网络的基本工作原理
神经网络由基本的神经元组成，图1-13就是一个神经元的数学/计算模型，便于我们用程序来实现。

<img src="https://aiedugithub4a2.blob.core.windows.net/a2-images/Images/1/NeuranCell.png" ch="500" />

图1-13 神经元计算模型

## 输入 input

$(x_1,x_2,x_3)$ 是外界输入信号，一般是一个训练数据样本的多个属性，比如，我们要预测一套房子的价格，那么在房屋价格数据样本中，$x_1$ 可能代表了面积，$x_2$ 可能代表地理位置，$x_3$ 可能代表朝向。另外一个例子是，$(x_1,x_2,x_3)$ 分别代表了(红,绿,蓝)三种颜色，而此神经元用于识别输入的信号是暖色还是冷色。

## 权重 weights

$(w_1,w_2,w_3)$ 是每个输入信号的权重值，以上面的 $(x_1,x_2,x_3)$ 的例子来说，$x_1$ 的权重可能是 $0.92$，$x_2$ 的权重可能是 $0.2$，$x_3$ 的权重可能是 $0.03$。当然权重值相加之后可以不是 $1$。

## 偏移 bias

还有个 $b$ 是怎么来的？一般的书或者博客上会告诉你那是因为 $y=wx+b$，$b$ 是偏移值，使得直线能够沿 $Y$ 轴上下移动。这是用结果来解释原因，并非 $b$ 存在的真实原因。从生物学上解释，在脑神经细胞中，一定是输入信号的电平/电流大于某个临界值时，神经元细胞才会处于兴奋状态，这个 $b$ 实际就是那个临界值。亦即当：

$$w_1 \cdot x_1 + w_2 \cdot x_2 + w_3 \cdot x_3 \geq t$$

时，该神经元细胞才会兴奋。我们把t挪到等式左侧来，变成$(-t)$，然后把它写成 $b$，变成了：

$$w_1 \cdot x_1 + w_2 \cdot x_2 + w_3 \cdot x_3 + b \geq 0$$

于是 $b$ 诞生了！

## 求和计算 sum

$$
\begin{aligned}
Z &= w_1 \cdot x_1 + w_2 \cdot x_2 + w_3 \cdot x_3 + b \\\\
&= \sum_{i=1}^m(w_i \cdot x_i) + b
\end{aligned}
$$

在上面的例子中 $m=3$。我们把$w_i \cdot x_i$变成矩阵运算的话，就变成了：

$$Z = W \cdot X + b$$

## 激活函数 activation

求和之后，神经细胞已经处于兴奋状态了，已经决定要向下一个神经元传递信号了，但是要传递多强烈的信号，要由激活函数来确定：

$$A=\sigma{(Z)}$$

如果激活函数是一个阶跃信号的话，会像继电器开合一样咔咔的开启和闭合，在生物体中是不可能有这种装置的，而是一个渐渐变化的过程。所以一般激活函数都是有一个渐变的过程，也就是说是个曲线，如图1-14所示。

<img src="https://aiedugithub4a2.blob.core.windows.net/a2-images/Images/1/activation.png" />

图1-14 激活函数图像

至此，一个神经元的工作过程就在电光火石般的一瞬间结束了。

## 小结

- 一个神经元可以有多个输入。
- 一个神经元只能有一个输出，这个输出可以同时输入给多个神经元。
- 一个神经元的 $w$ 的数量和输入的数量一致。
- 一个神经元只有一个 $b$。
- $w$ 和 $b$ 有人为的初始值，在训练过程中被不断修改。
- $A$ 可以等于 $Z$，即激活函数不是必须有的。
- 一层神经网络中的所有神经元的激活函数必须一致。

# 2.1 反向传播与梯度下降

## 神经网络中的三个基本概念

这三大概念是：反向传播，梯度下降，损失函数。

神经网络训练的最基本的思想就是：先“猜”一个结果，称为预测结果 $a$，看看这个预测结果和事先标记好的训练集中的真实结果 $y$ 之间的差距，然后调整策略，再试一次，这一次就不是“猜”了，而是有依据地向正确的方向靠近。如此反复多次，一直到预测结果和真实结果之间相差无几，亦即 $|a-y|\rightarrow 0$，就结束训练。

在神经网络训练中，我们把“猜”叫做初始化，可以随机，也可以根据以前的经验给定初始值。即使是“猜”，也是有技术含量的。
## 总结

简单总结一下反向传播与梯度下降的基本工作原理：

1. 初始化；
2. 正向计算；
3. 损失函数为我们提供了计算损失的方法；
4. 梯度下降是在损失函数基础上向着损失最小的点靠近而指引了网络权重调整的方向；
5. 反向传播把损失值反向传给神经网络的每一层，让每一层都根据损失值反向调整权重；
6. Go to 2，直到精度足够好（比如损失函数值小于 $0.001$）。

# $2.2 线性反向传播
## 参考资料

http://colah.github.io/posts/2015-08-Backprop/

# 2.3非线性反向传播
## 正向过程

1. 第1个人，输入层，随机输入第一个 $x$ 值，$x$ 的取值范围 $(1,10]$，假设第一个数是 $2$；
2. 第2个人，第一层网络计算，接收第1个人传入 $x$ 的值，计算：$a=x^2$；
3. 第3个人，第二层网络计算，接收第2个人传入 $a$ 的值，计算：$b=\ln (a)$；
4. 第4个人，第三层网络计算，接收第3个人传入 $b$ 的值，计算：$c=\sqrt{b}$；
5. 第5个人，输出层，接收第4个人传入 $c$ 的值

## 反向过程

6. 第5个人，计算 $y$ 与 $c$ 的差值：$\Delta c = c - y$，传回给第4个人
7. 第4个人，接收第5个人传回$\Delta c$，计算 $\Delta b = \Delta c \cdot 2\sqrt{b}$
8. 第3个人，接收第4个人传回$\Delta b$，计算 $\Delta a = \Delta b \cdot a$
9. 第2个人，接收第3个人传回$\Delta a$，计算 $\Delta x = \frac{\Delta}{2x}$
10. 第1个人，接收第2个人传回$\Delta x$，更新 $x \leftarrow x - \Delta x$，回到第1步

提出问题：假设我们想最后得到 $c=2.13$ 的值，$x$ 应该是多少？（误差小于 $0.001$ 即可）

## 2.3.1 数学解析解

$$c=\sqrt{b}=\sqrt{\ln(a)}=\sqrt{\ln(x^2)}=2.13$$
$$x = 9.6653$$

## 2.3.2 梯度迭代解

$$
\frac{da}{dx}=\frac{d(x^2)}{dx}=2x=\frac{\Delta a}{\Delta x} \tag{1}
$$
$$
\frac{db}{da} =\frac{d(\ln{a})}{da} =\frac{1}{a} = \frac{\Delta b}{\Delta a} \tag{2}
$$
$$
\frac{dc}{db}=\frac{d(\sqrt{b})}{db}=\frac{1}{2\sqrt{b}}=\frac{\Delta c}{\Delta b} \tag{3}
$$
因此得到如下一组公式，可以把最后一层 $\Delta c$ 的误差一直反向传播给最前面的 $\Delta x$，从而更新 $x$ 值：
$$
\Delta c = c - y \tag{4}
$$
$$
\Delta b = \Delta c \cdot 2\sqrt{b}  \tag{根据式3}
$$
$$
\Delta a = \Delta b \cdot a  \tag{根据式2}
$$
$$
\Delta x = \Delta a / 2x \tag{根据式1}
$$

我们给定初始值 $x=2$，$\Delta x=0$，依次计算结果如表2-2。

表2-2 正向与反向的迭代计算

|方向|公式|迭代1|迭代2|迭代3|迭代4|迭代5|
|---|---|---|---|---|---|---|
|正向|$x=x-\Delta x$|2|4.243|7.344|9.295|9.665|
|正向|$a=x^2$|4|18.005|53.934|86.404|93.233|
|正向|$b=\ln(a)$|1.386|2.891|3.988|4.459|4.535|
|正向|$c=\sqrt{b}$|1.177|1.700|1.997|2.112|2.129|
||标签值y|2.13|2.13|2.13|2.13|2.13|
|反向|$\Delta c = c - y$|-0.953|-0.430|-0.133|-0.018||
|反向|$\Delta b = \Delta c \cdot 2\sqrt{b}$|-2.243|-1.462|-0.531|-0.078||
|反向|$\Delta a = \Delta b \cdot a$|-8.973|-26.317|-28.662|-6.698||
|反向|$\Delta x = \Delta a / 2x$|-2.243|-3.101|-1.951|-0.360||

表2-2，先看“迭代-1”列，从上到下是一个完整的正向+反向的过程，最后一行是 $-2.243$，回到“迭代-2”列的第一行，$2-(-2.243)=4.243$，然后继续向下。到第5轮时，正向计算得到的 $c=2.129$，非常接近 $2.13$ 了，迭代结束。

运行示例代码可以得到如下结果：

```
how to play: 1) input x, 2) calculate c, 3) input target number but not faraway from c
input x as initial number(1.2,10), you can try 1.3:
2
c=1.177410
input y as target number(0.5,2), you can try 1.8:
2.13
forward...
x=2.000000,a=4.000000,b=1.386294,c=1.177410
backward...
delta_c=-0.952590, delta_b=-2.243178, delta_a=-8.972712, delta_x=-2.243178
......
forward...
x=9.655706,a=93.232666,b=4.535098,c=2.129577
backward...
done!
```

为节省篇幅只列出了第一步和最后一步（第5步）的结果，第一步时`c=1.177410`，最后一步时`c=2.129577`，停止迭代。

# 2.4梯度下降
## 2.4.1 从自然现象中理解梯度下降

在大多数文章中，都以“一个人被困在山上，需要迅速下到谷底”来举例，这个人会“寻找当前所处位置最陡峭的地方向下走”。这个例子中忽略了安全因素，这个人不可能沿着最陡峭的方向走，要考虑坡度。

在自然界中，梯度下降的最好例子，就是泉水下山的过程：

1. 水受重力影响，会在当前位置，沿着最陡峭的方向流动，有时会形成瀑布（梯度下降）；
2. 水流下山的路径不是唯一的，在同一个地点，有可能有多个位置具有同样的陡峭程度，而造成了分流（可以得到多个解）；
3. 遇到坑洼地区，有可能形成湖泊，而终止下山过程（不能得到全局最优解，而是局部最优解）。

## 2.4.2 梯度下降的数学理解

梯度下降的数学公式：

$$\theta_{n+1} = \theta_{n} - \eta \cdot \nabla J(\theta) \tag{1}$$

其中：

- $\theta_{n+1}$：下一个值；
- $\theta_n$：当前值；
- $-$：减号，梯度的反向；
- $\eta$：学习率或步长，控制每一步走的距离，不要太快以免错过了最佳景点，不要太慢以免时间太长；
- $\nabla$：梯度，函数当前位置的最快上升点；
- $J(\theta)$：函数。

## 2.4.3梯度下降的三要素

1. 当前点；
2. 方向；
3. 步长。

## 2.4.4为什么说是“梯度下降”？

“梯度下降”包含了两层含义：

1. 梯度：函数当前位置的最快上升点；
2. 下降：与导数相反的方向，用数学语言描述就是那个减号。

亦即与上升相反的方向运动，就是下降。

# 3.1损失函数
##  概念

在各种材料中经常看到的中英文词汇有：误差，偏差，Error，Cost，Loss，损失，代价......意思都差不多，在本书中，使用“损失函数”和“Loss Function”这两个词汇，具体的损失函数符号用 $J$ 来表示，误差值用 $loss$ 表示。

“损失”就是所有样本的“误差”的总和，亦即（$m$ 为样本数）：

$$损失 = \sum^m_{i=1}误差_i$$

$$J = \sum_{i=1}^m loss_i$$

在黑盒子的例子中，我们如果说“某个样本的损失”是不对的，只能说“某个样本的误差”，因为样本是一个一个计算的。如果我们把神经网络的参数调整到完全满足独立样本的输出误差为 $0$，通常会令其它样本的误差变得更大，这样作为误差之和的损失函数值，就会变得更大。所以，我们通常会在根据某个样本的误差调整权重后，计算一下整体样本的损失函数值，来判定网络是不是已经训练到了可接受的状态。

## 损失函数的作用

损失函数的作用，就是计算神经网络每次迭代的前向计算结果与真实值的差距，从而指导下一步的训练向正确的方向进行。

如何使用损失函数呢？具体步骤：

1. 用随机值初始化前向计算公式的参数；
2. 代入样本，计算输出的预测值；
3. 用损失函数计算预测值和标签值（真实值）的误差；
4. 根据损失函数的导数，沿梯度最小方向将误差回传，修正前向计算公式中的各个权重值；
5. 进入第2步重复, 直到损失函数值达到一个满意的值就停止迭代。

# 3.2均方差损失函数
MSE - Mean Square Error。

该函数就是最直观的一个损失函数了，计算预测值和真实值之间的欧式距离。预测值和真实值越接近，两者的均方差就越小。

均方差函数常用于线性回归(linear regression)，即函数拟合(function fitting)。公式如下：

$$
loss = {1 \over 2}(z-y)^2 \tag{单样本}
$$

$$
J=\frac{1}{2m} \sum_{i=1}^m (z_i-y_i)^2 \tag{多样本}
$$

##  工作原理

要想得到预测值 $a$ 与真实值 $y$ 的差距，最朴素的想法就是用 $Error=a_i-y_i$。

对于单个样本来说，这样做没问题，但是多个样本累计时，$a_i-y_i$ 可能有正有负，误差求和时就会导致相互抵消，从而失去价值。所以有了绝对值差的想法，即 $Error=|a_i-y_i|$ 。这看上去很简单，并且也很理想，那为什么还要引入均方差损失函数呢？两种损失函数的比较如表3-1所示。

表3-1 绝对值损失函数与均方差损失函数的比较

|样本标签值|样本预测值|绝对值损失函数|均方差损失函数|
|------|------|------|------|
|$[1,1,1]$|$[1,2,3]$|$(1-1)+(2-1)+(3-1)=3$|$(1-1)^2+(2-1)^2+(3-1)^2=5$|
|$[1,1,1]$|$[1,3,3]$|$(1-1)+(3-1)+(3-1)=4$|$(1-1)^2+(3-1)^2+(3-1)^2=8$|
|||$4/3=1.33$|$8/5=1.6$|

可以看到5比3已经大了很多，8比4大了一倍，而8比5也放大了某个样本的局部损失对全局带来的影响，用术语说，就是“对某些偏离大的样本比较敏感”，从而引起监督训练过程的足够重视，以便回传误差。

# 3.3交叉熵损失函数
交叉熵（Cross Entropy）是Shannon信息论中一个重要概念，主要用于度量两个概率分布间的差异性信息。在信息论中，交叉熵是表示两个概率分布 $p,q$ 的差异，其中 $p$ 表示真实分布，$q$ 表示预测分布，那么 $H(p,q)$ 就称为交叉熵：

$$H(p,q)=\sum_i p_i \cdot \ln {1 \over q_i} = - \sum_i p_i \ln q_i \tag{1}$$

交叉熵可在神经网络中作为损失函数，$p$ 表示真实标记的分布，$q$ 则为训练后的模型的预测标记分布，交叉熵损失函数可以衡量 $p$ 与 $q$ 的相似性。
